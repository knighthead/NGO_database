{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import copy\n",
    "import unicodecsv as csv\n",
    "import re\n",
    "import requests\n",
    "import random\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import OrderedDict\n",
    "\n",
    "headers_of_request = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.87 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "    'Accept-Encoding': 'gzip, deflate, sdch',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Host': 'www.wango.org'\n",
    "}\n",
    "\n",
    "regionIDs = OrderedDict([\n",
    "    (5, 'South-America'),\n",
    "    (9, 'Oceania'),\n",
    "    (11, 'Western Africa'),\n",
    "    (13, 'Central-America'),\n",
    "    (14, 'Eastern Africa'),\n",
    "    (15, 'Northern Africa'),\n",
    "    (17, 'Middle Africa'),\n",
    "    (18, 'Southern Africa'),\n",
    "    (21, 'Northern-America'),\n",
    "    (29, 'Caribbean'),\n",
    "    (30, 'Eastern Asia'),\n",
    "    (35, 'South-Eastern Asia'),\n",
    "    (39, 'Southern-Europe'),\n",
    "    (62, 'South-Central Asia'),\n",
    "    (145, 'Western Asia'),\n",
    "    (151, 'Eastern Europe'),\n",
    "    (154, 'Nothern Europe'),\n",
    "    (155, 'Western Europe')\n",
    "])\n",
    "'''\n",
    "regionIDs = OrderedDict([\n",
    "    (11, 'Western Africa')\n",
    "])\n",
    "'''\n",
    "countryIDs = OrderedDict([\n",
    "    (5, '32,68,76,152,170,218,238,254,328,600,604,740,858,862,0'),\n",
    "    (9, '16,36,90,184,242,258,296,316,520,540,548,554,570,574,580,583,584,585,598,612,772,776,798,876,882,0'),\n",
    "    (11, '132,204,270,288,324,384,430,466,478,562,566,624,654,686,694,768,854,0'),\n",
    "    (13, '84,188,222,320,340,484,558,591,0'),\n",
    "    (14, '108,174,175,231,232,262,404,450,454,480,508,638,646,690,706,716,800,834,894,0'),\n",
    "    (15, '12,434,504,732,736,788,818,0'),\n",
    "    (17, '24,120,140,148,178,180,226,266,678,0'),\n",
    "    (18, '72,426,516,710,748,0'),\n",
    "    (21, '60,124,304,666,840,0'),\n",
    "    (29, '28,44,52,92,136,192,212,214,308,312,332,388,474,500,530,533,630,659,660,662,670,780,796,850,0'),\n",
    "    (30, '156,344,392,408,410,446,496,895,0'),\n",
    "    (35, '96,104,116,360,418,458,608,626,702,704,764,0'),\n",
    "    (39, '8,20,70,191,292,300,336,380,470,620,674,705,724,807,896,897,898,0'),\n",
    "    (62, '4,50,64,144,356,364,398,417,462,524,586,762,795,860,0'),\n",
    "    (145, '31,48,51,196,268,275,368,376,400,414,422,512,634,682,760,784,792,887,0'),\n",
    "    (151, '100,112,203,348,498,616,642,643,703,804,0'),\n",
    "    (154, '208,233,234,246,352,372,428,440,578,744,752,826,830,833,0'),\n",
    "    (155, '40,56,250,276,438,442,492,528,756,0')\n",
    "])\n",
    "\n",
    "ccIDs = OrderedDict([\n",
    "    (5, 'cc3300'),\n",
    "    (9, '2586BA'),\n",
    "    (11, 'ffcc00'),\n",
    "    (13, '51ae63'),\n",
    "    (14, 'AB875'),\n",
    "    (15, '8AC2E8'),\n",
    "    (17, 'ff9900'),\n",
    "    (18, 'BFB07D'),\n",
    "    (21, 'F85038'),\n",
    "    (29, 'A5D0ED'),\n",
    "    (30, 'F85038'),\n",
    "    (35, 'cc3300'),\n",
    "    (39, '2586BA'),\n",
    "    (62, 'ffcc00'),\n",
    "    (145, '51ae63'),\n",
    "    (151, 'ABC875'),\n",
    "    (154, '8AC2E8'),\n",
    "    (155, 'ff9900')\n",
    "])\n",
    "\n",
    "def relevant_links(tag):\n",
    "    a = False\n",
    "    if (tag.name==u'a' and tag.has_attr('href')):\n",
    "        if (tag['href'].find('javascript:loadOrg(')!=-1):\n",
    "            a = True\n",
    "    return a\n",
    "\n",
    "s = requests.Session()\n",
    "s.headers.update(headers_of_request)\n",
    "BaseUrl = 'http://www.wango.org'\n",
    "SubUrl = '/resources.aspx?section=ngodir'\n",
    "\n",
    "output_db = []\n",
    "ngo_entry = {\n",
    "    u'region_id': -1,\n",
    "    u'region': '',\n",
    "    u'country': '',\n",
    "    u'city': '',\n",
    "    u'ngo_name': '',\n",
    "    u'ngo_id': -1,\n",
    "}\n",
    "\n",
    "for key in regionIDs:\n",
    "    region = regionIDs[key]\n",
    "    ngo_entry['region_id'] = key\n",
    "    ngo_entry['region'] = region\n",
    "    # Initial get and payload\n",
    "    init_payload = OrderedDict([('sub','region'),\n",
    "                                ('regionID',key),('col', ccIDs[key])])\n",
    "    ngo_initial_response = s.get(url=(BaseUrl + SubUrl),params=init_payload)\n",
    "    print \"RegionID: \", key, \". Initial request's response code: \",ngo_initial_response.status_code\n",
    "    # Filtered post.\n",
    "    request_item = OrderedDict([\n",
    "        (\"Countries\", countryIDs[key]),\n",
    "        (\"InterestAreas\", \"Environment\"),\n",
    "        (\"currpage\", 1),\n",
    "    ])\n",
    "    referer = {'Referer': ngo_initial_response.url}\n",
    "    payload2 = OrderedDict([('sub','list'),('regionID', key),\n",
    "                            ('col', ccIDs[key])])\n",
    "    ngo_filtered_response = s.post(url=(BaseUrl + SubUrl),params=payload2,\n",
    "                                   data=request_item, headers=referer)\n",
    "    print \"RegionID: \", key, \". Initial filtered request's response code: \",ngo_filtered_response.status_code\n",
    "    ngo_soup = BeautifulSoup(ngo_filtered_response.content.decode('utf-8'),'lxml')\n",
    "    filtered_content = ngo_soup.find(u'div',{u'class': u'content'})\n",
    "    \n",
    "    #determining the number of pages\n",
    "    num_of_pages = -1\n",
    "    try:\n",
    "        filtered_pages_content = filtered_content.find(u'td',\n",
    "                                                       {u'valign': u'top'}).find(u'div',{u'align': u'left'})\n",
    "        if (0 != len(filtered_pages_content.findAll(u'a'))):\n",
    "            for link in filtered_pages_content.findAll(u'a'):\n",
    "                num_of_pages += 1\n",
    "        else:\n",
    "            num_of_pages = 1\n",
    "    except:\n",
    "        numf_of_pages = 1\n",
    "    print \"Region \",key,\": Number of pages: \",num_of_pages\n",
    "        \n",
    "    for i in range(1,num_of_pages+1):\n",
    "        if (i > 1):\n",
    "            \n",
    "            request_item[\"currpage\"] = i\n",
    "            old_url = ngo_filtered_response.url\n",
    "            referer['Referer'] = old_url\n",
    "            ngo_filtered_response = s.post(url=(BaseUrl+SubUrl),params=payload2,\n",
    "                                          data=request_item, headers=referer)\n",
    "            print \"RegionID: \", key, \". Page \",i,\" filtered request's response code: \",ngo_filtered_response.status_code\n",
    "            ngo_soup = BeautifulSoup(ngo_filtered_response.content.decode('utf-8'),'lxml')\n",
    "            filtered_content = ngo_soup.find(u'div',{u'class': u'content'})\n",
    "            try:\n",
    "                filtered_pages_content = filtered_content.find(u'td',\n",
    "                                                               {u'valign': u'top'}).find(u'div',{u'align': u'left'})\n",
    "            except:\n",
    "                print \"Error on page \" + str(i)\n",
    "                with codecs.open('error_response.txt','wb','utf-8') as outfile:\n",
    "                    outfile.write(ngo_soup.prettify())\n",
    "                # print filtered_content.find('td',{'valign': 'top'}).find('div',{'align': 'left'})\n",
    "                raise\n",
    "        for link in filtered_content.findAll(relevant_links):\n",
    "            ngo_entry['ngo_id'] = int(float(re.search(\"javascript:loadOrg((.+?));\",\n",
    "                                                      link['href']).group(1)[2:-2]))\n",
    "            ngo_entry['ngo_name'] = link.string\n",
    "            id_value = u's'+str(ngo_entry['ngo_id'])\n",
    "            for string in filtered_content.find(u'div',{u'id': id_value}).stripped_strings:\n",
    "                ngo_entry['city'] = string.split(',')[0].strip()\n",
    "                ngo_entry['country'] = string.split(',')[1].strip()\n",
    "            output_db.append(ngo_entry.copy())\n",
    "        time.sleep(5)\n",
    "\n",
    "with open('ngo_database.csv','wb') as outfile:\n",
    "    csv_headers = []\n",
    "    for key,value in ngo_entry.items():\n",
    "        csv_headers.append(key)\n",
    "    writer = csv.DictWriter(outfile,delimiter=';', quotechar='\"',fieldnames=csv_headers,encoding='utf-8')\n",
    "    writer.writeheader()\n",
    "    for dict_one in output_db:\n",
    "        writer.writerow(dict_one)\n",
    "    # http://www.crummy.com/software/BeautifulSoup/bs4/doc/#going-down\n",
    "    \n",
    "print \"Finished.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
